{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4q368ftQ9Wp1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz7v7Pux92z1",
        "outputId": "30a78367-f054-4012-b998-243b0ed44a9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set the path to the main folder containing train, test, and valid folders\n",
        "data_dir = '/content/drive/MyDrive/Flower-Classification-1'\n",
        "\n",
        "batch_size = 32\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Use the image_dataset_from_directory function to load the datasets\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=data_dir + '/train',\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    shuffle=True,\n",
        "    label_mode= 'categorical',\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=data_dir + '/test',\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    label_mode= 'categorical',\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=data_dir + '/valid',\n",
        "    batch_size=batch_size,\n",
        "    image_size=image_size,\n",
        "    label_mode= 'categorical',\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCuPpXBE954T",
        "outputId": "b35157a3-7fd7-4271-cc0e-db5cce0c771b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 files belonging to 5 classes.\n",
            "Found 432 files belonging to 5 classes.\n",
            "Found 861 files belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir =data_dir + '/valid'\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(64, 64, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.5))  # Increased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.6))  # Increased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.7))  # Increased dropout\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.Dropout(0.6))  # Increased dropout\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile and train the model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# ... (previous code remains the same)\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with augmented data and increased dropout\n",
        "history = cnn.fit(train_dataset, validation_data=valid_dataset, epochs=50, callbacks=[early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TlhCzU8-HLI",
        "outputId": "324ef8b9-9b43-47d4-b2ba-ff95e7531c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 images belonging to 5 classes.\n",
            "Found 861 images belonging to 5 classes.\n",
            "Epoch 1/50\n",
            "95/95 [==============================] - 24s 236ms/step - loss: 4.5906 - accuracy: 0.2432 - val_loss: 3.3834 - val_accuracy: 0.2253\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - 22s 235ms/step - loss: 4.0193 - accuracy: 0.2899 - val_loss: 3.7024 - val_accuracy: 0.2253\n",
            "Epoch 3/50\n",
            "95/95 [==============================] - 25s 263ms/step - loss: 3.5914 - accuracy: 0.3274 - val_loss: 4.1631 - val_accuracy: 0.2253\n",
            "Epoch 4/50\n",
            "95/95 [==============================] - 21s 225ms/step - loss: 3.3601 - accuracy: 0.3479 - val_loss: 3.3818 - val_accuracy: 0.2544\n",
            "Epoch 5/50\n",
            "95/95 [==============================] - 22s 235ms/step - loss: 3.1446 - accuracy: 0.3582 - val_loss: 2.9615 - val_accuracy: 0.2753\n",
            "Epoch 6/50\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 2.9841 - accuracy: 0.3844 - val_loss: 2.1700 - val_accuracy: 0.3961\n",
            "Epoch 7/50\n",
            "95/95 [==============================] - 23s 237ms/step - loss: 2.8964 - accuracy: 0.3860 - val_loss: 2.2751 - val_accuracy: 0.3763\n",
            "Epoch 8/50\n",
            "95/95 [==============================] - 22s 233ms/step - loss: 2.7795 - accuracy: 0.3943 - val_loss: 2.1352 - val_accuracy: 0.3972\n",
            "Epoch 9/50\n",
            "95/95 [==============================] - 22s 230ms/step - loss: 2.6646 - accuracy: 0.4032 - val_loss: 2.1835 - val_accuracy: 0.3926\n",
            "Epoch 10/50\n",
            "95/95 [==============================] - 22s 229ms/step - loss: 2.5674 - accuracy: 0.4115 - val_loss: 2.0556 - val_accuracy: 0.4030\n",
            "Epoch 11/50\n",
            "95/95 [==============================] - 23s 237ms/step - loss: 2.5351 - accuracy: 0.4182 - val_loss: 2.0308 - val_accuracy: 0.4053\n",
            "Epoch 12/50\n",
            "95/95 [==============================] - 22s 231ms/step - loss: 2.4745 - accuracy: 0.4095 - val_loss: 1.9652 - val_accuracy: 0.3961\n",
            "Epoch 13/50\n",
            "95/95 [==============================] - 22s 231ms/step - loss: 2.4157 - accuracy: 0.4129 - val_loss: 1.9321 - val_accuracy: 0.4007\n",
            "Epoch 14/50\n",
            "95/95 [==============================] - 25s 266ms/step - loss: 2.3563 - accuracy: 0.4278 - val_loss: 1.8765 - val_accuracy: 0.4251\n",
            "Epoch 15/50\n",
            "95/95 [==============================] - 22s 227ms/step - loss: 2.3571 - accuracy: 0.4218 - val_loss: 1.8749 - val_accuracy: 0.4158\n",
            "Epoch 16/50\n",
            "95/95 [==============================] - 22s 230ms/step - loss: 2.2152 - accuracy: 0.4294 - val_loss: 1.8813 - val_accuracy: 0.4077\n",
            "Epoch 17/50\n",
            "95/95 [==============================] - 22s 236ms/step - loss: 2.2732 - accuracy: 0.4218 - val_loss: 1.9012 - val_accuracy: 0.4204\n",
            "Epoch 18/50\n",
            "95/95 [==============================] - 22s 233ms/step - loss: 2.1427 - accuracy: 0.4347 - val_loss: 1.8222 - val_accuracy: 0.4111\n",
            "Epoch 19/50\n",
            "95/95 [==============================] - 24s 252ms/step - loss: 2.1142 - accuracy: 0.4470 - val_loss: 1.8211 - val_accuracy: 0.4193\n",
            "Epoch 20/50\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 2.1201 - accuracy: 0.4450 - val_loss: 1.7853 - val_accuracy: 0.4181\n",
            "Epoch 21/50\n",
            "95/95 [==============================] - 22s 232ms/step - loss: 2.0287 - accuracy: 0.4334 - val_loss: 1.8013 - val_accuracy: 0.4309\n",
            "Epoch 22/50\n",
            "95/95 [==============================] - 25s 259ms/step - loss: 2.0267 - accuracy: 0.4394 - val_loss: 1.7966 - val_accuracy: 0.4228\n",
            "Epoch 23/50\n",
            "95/95 [==============================] - 25s 260ms/step - loss: 1.9751 - accuracy: 0.4516 - val_loss: 1.8087 - val_accuracy: 0.4216\n",
            "Epoch 24/50\n",
            "95/95 [==============================] - 22s 227ms/step - loss: 1.9582 - accuracy: 0.4433 - val_loss: 1.7873 - val_accuracy: 0.4344\n",
            "Epoch 25/50\n",
            "95/95 [==============================] - 21s 226ms/step - loss: 1.9762 - accuracy: 0.4533 - val_loss: 1.7534 - val_accuracy: 0.4402\n",
            "Epoch 26/50\n",
            "95/95 [==============================] - 24s 251ms/step - loss: 1.9017 - accuracy: 0.4689 - val_loss: 1.7391 - val_accuracy: 0.4390\n",
            "Epoch 27/50\n",
            "95/95 [==============================] - 23s 239ms/step - loss: 1.9461 - accuracy: 0.4476 - val_loss: 1.7445 - val_accuracy: 0.4402\n",
            "Epoch 28/50\n",
            "95/95 [==============================] - 22s 231ms/step - loss: 1.8289 - accuracy: 0.4718 - val_loss: 1.7332 - val_accuracy: 0.4379\n",
            "Epoch 29/50\n",
            "95/95 [==============================] - 25s 264ms/step - loss: 1.8845 - accuracy: 0.4569 - val_loss: 1.7357 - val_accuracy: 0.4344\n",
            "Epoch 30/50\n",
            "95/95 [==============================] - 24s 248ms/step - loss: 1.8461 - accuracy: 0.4546 - val_loss: 1.7015 - val_accuracy: 0.4390\n",
            "Epoch 31/50\n",
            "95/95 [==============================] - 23s 241ms/step - loss: 1.8465 - accuracy: 0.4612 - val_loss: 1.7276 - val_accuracy: 0.4355\n",
            "Epoch 32/50\n",
            "95/95 [==============================] - 22s 231ms/step - loss: 1.8034 - accuracy: 0.4751 - val_loss: 1.7299 - val_accuracy: 0.4239\n",
            "Epoch 33/50\n",
            "95/95 [==============================] - 22s 234ms/step - loss: 1.7649 - accuracy: 0.4814 - val_loss: 1.7113 - val_accuracy: 0.4425\n",
            "Epoch 34/50\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 1.7772 - accuracy: 0.4871 - val_loss: 1.6870 - val_accuracy: 0.4472\n",
            "Epoch 35/50\n",
            "95/95 [==============================] - 22s 233ms/step - loss: 1.7670 - accuracy: 0.4874 - val_loss: 1.6864 - val_accuracy: 0.4355\n",
            "Epoch 36/50\n",
            "95/95 [==============================] - 22s 233ms/step - loss: 1.7518 - accuracy: 0.4725 - val_loss: 1.6995 - val_accuracy: 0.4367\n",
            "Epoch 37/50\n",
            "95/95 [==============================] - 25s 263ms/step - loss: 1.7355 - accuracy: 0.4848 - val_loss: 1.6681 - val_accuracy: 0.4355\n",
            "Epoch 38/50\n",
            "95/95 [==============================] - 22s 229ms/step - loss: 1.6977 - accuracy: 0.4990 - val_loss: 1.6676 - val_accuracy: 0.4355\n",
            "Epoch 39/50\n",
            "95/95 [==============================] - 23s 246ms/step - loss: 1.6957 - accuracy: 0.5070 - val_loss: 1.6525 - val_accuracy: 0.4413\n",
            "Epoch 40/50\n",
            "95/95 [==============================] - 24s 251ms/step - loss: 1.6449 - accuracy: 0.5027 - val_loss: 1.6593 - val_accuracy: 0.4413\n",
            "Epoch 41/50\n",
            "95/95 [==============================] - 24s 249ms/step - loss: 1.6733 - accuracy: 0.4851 - val_loss: 1.6284 - val_accuracy: 0.4599\n",
            "Epoch 42/50\n",
            "95/95 [==============================] - 23s 241ms/step - loss: 1.6368 - accuracy: 0.5179 - val_loss: 1.6272 - val_accuracy: 0.4611\n",
            "Epoch 43/50\n",
            "95/95 [==============================] - 24s 249ms/step - loss: 1.6270 - accuracy: 0.5186 - val_loss: 1.6380 - val_accuracy: 0.4553\n",
            "Epoch 44/50\n",
            "95/95 [==============================] - 21s 224ms/step - loss: 1.6417 - accuracy: 0.5036 - val_loss: 1.6610 - val_accuracy: 0.4413\n",
            "Epoch 45/50\n",
            "95/95 [==============================] - 23s 245ms/step - loss: 1.6115 - accuracy: 0.5239 - val_loss: 1.6615 - val_accuracy: 0.4472\n",
            "Epoch 46/50\n",
            "95/95 [==============================] - 24s 251ms/step - loss: 1.5817 - accuracy: 0.5355 - val_loss: 1.6277 - val_accuracy: 0.4518\n",
            "Epoch 47/50\n",
            "95/95 [==============================] - 22s 232ms/step - loss: 1.5693 - accuracy: 0.5179 - val_loss: 1.6368 - val_accuracy: 0.4541\n",
            "Epoch 48/50\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 1.5705 - accuracy: 0.5437 - val_loss: 1.6359 - val_accuracy: 0.4460\n",
            "Epoch 49/50\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 1.5341 - accuracy: 0.5361 - val_loss: 1.6181 - val_accuracy: 0.4646\n",
            "Epoch 50/50\n",
            "95/95 [==============================] - 22s 232ms/step - loss: 1.5319 - accuracy: 0.5378 - val_loss: 1.6073 - val_accuracy: 0.4669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir =data_dir + '/valid'\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(64, 64, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.4))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.5))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.6))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.Dropout(0.5))  # Decreased dropout\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# ... (previous code remains unchanged)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define Early Stopping Callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with augmented data and adjusted dropout\n",
        "history = cnn.fit(train_dataset, validation_data=valid_dataset, epochs=50, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVBLHKgDkczJ",
        "outputId": "9ecd9b40-d366-4339-8899-1678527f9274"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 images belonging to 5 classes.\n",
            "Found 861 images belonging to 5 classes.\n",
            "Epoch 1/50\n",
            "95/95 [==============================] - 1218s 13s/step - loss: 3.4524 - accuracy: 0.2744 - val_loss: 3.2773 - val_accuracy: 0.2253\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - 49s 512ms/step - loss: 2.9205 - accuracy: 0.3509 - val_loss: 3.8236 - val_accuracy: 0.2253\n",
            "Epoch 3/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 2.7460 - accuracy: 0.3943 - val_loss: 2.8891 - val_accuracy: 0.2288\n",
            "Epoch 4/50\n",
            "95/95 [==============================] - 46s 476ms/step - loss: 2.6226 - accuracy: 0.3979 - val_loss: 2.8759 - val_accuracy: 0.2753\n",
            "Epoch 5/50\n",
            "95/95 [==============================] - 43s 451ms/step - loss: 2.4574 - accuracy: 0.4142 - val_loss: 2.2460 - val_accuracy: 0.3670\n",
            "Epoch 6/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 2.3567 - accuracy: 0.4155 - val_loss: 2.0677 - val_accuracy: 0.3972\n",
            "Epoch 7/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 2.2798 - accuracy: 0.4298 - val_loss: 2.0524 - val_accuracy: 0.3984\n",
            "Epoch 8/50\n",
            "95/95 [==============================] - 44s 460ms/step - loss: 2.1652 - accuracy: 0.4533 - val_loss: 1.9647 - val_accuracy: 0.4077\n",
            "Epoch 9/50\n",
            "95/95 [==============================] - 47s 496ms/step - loss: 2.1023 - accuracy: 0.4546 - val_loss: 1.8992 - val_accuracy: 0.4297\n",
            "Epoch 10/50\n",
            "95/95 [==============================] - 45s 473ms/step - loss: 2.1299 - accuracy: 0.4576 - val_loss: 1.9166 - val_accuracy: 0.4390\n",
            "Epoch 11/50\n",
            "95/95 [==============================] - 47s 498ms/step - loss: 1.9896 - accuracy: 0.4758 - val_loss: 1.7603 - val_accuracy: 0.4762\n",
            "Epoch 12/50\n",
            "95/95 [==============================] - 43s 456ms/step - loss: 2.0259 - accuracy: 0.4626 - val_loss: 1.7459 - val_accuracy: 0.4948\n",
            "Epoch 13/50\n",
            "95/95 [==============================] - 45s 476ms/step - loss: 1.9365 - accuracy: 0.4775 - val_loss: 1.7790 - val_accuracy: 0.4704\n",
            "Epoch 14/50\n",
            "95/95 [==============================] - 42s 442ms/step - loss: 1.8914 - accuracy: 0.4848 - val_loss: 1.7317 - val_accuracy: 0.4983\n",
            "Epoch 15/50\n",
            "95/95 [==============================] - 43s 455ms/step - loss: 1.8449 - accuracy: 0.4907 - val_loss: 1.7536 - val_accuracy: 0.4994\n",
            "Epoch 16/50\n",
            "95/95 [==============================] - 43s 451ms/step - loss: 1.8393 - accuracy: 0.4861 - val_loss: 1.7767 - val_accuracy: 0.4855\n",
            "Epoch 17/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 1.7989 - accuracy: 0.5000 - val_loss: 1.7054 - val_accuracy: 0.5029\n",
            "Epoch 18/50\n",
            "95/95 [==============================] - 43s 448ms/step - loss: 1.8080 - accuracy: 0.5017 - val_loss: 1.7229 - val_accuracy: 0.4901\n",
            "Epoch 19/50\n",
            "95/95 [==============================] - 42s 439ms/step - loss: 1.7550 - accuracy: 0.5142 - val_loss: 1.7100 - val_accuracy: 0.5075\n",
            "Epoch 20/50\n",
            "95/95 [==============================] - 41s 430ms/step - loss: 1.7211 - accuracy: 0.5139 - val_loss: 1.7342 - val_accuracy: 0.4994\n",
            "Epoch 21/50\n",
            "95/95 [==============================] - 41s 431ms/step - loss: 1.7146 - accuracy: 0.5189 - val_loss: 1.7601 - val_accuracy: 0.5017\n",
            "Epoch 22/50\n",
            "95/95 [==============================] - 41s 428ms/step - loss: 1.7041 - accuracy: 0.5176 - val_loss: 1.7065 - val_accuracy: 0.5110\n",
            "Epoch 23/50\n",
            "95/95 [==============================] - 44s 456ms/step - loss: 1.6720 - accuracy: 0.5239 - val_loss: 1.6884 - val_accuracy: 0.5145\n",
            "Epoch 24/50\n",
            "95/95 [==============================] - 43s 454ms/step - loss: 1.6337 - accuracy: 0.5394 - val_loss: 1.7424 - val_accuracy: 0.5110\n",
            "Epoch 25/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 1.6596 - accuracy: 0.5298 - val_loss: 1.7228 - val_accuracy: 0.5122\n",
            "Epoch 26/50\n",
            "95/95 [==============================] - 41s 427ms/step - loss: 1.6763 - accuracy: 0.5381 - val_loss: 1.7411 - val_accuracy: 0.5122\n",
            "Epoch 27/50\n",
            "95/95 [==============================] - 40s 426ms/step - loss: 1.5857 - accuracy: 0.5477 - val_loss: 1.6869 - val_accuracy: 0.5052\n",
            "Epoch 28/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 1.5691 - accuracy: 0.5394 - val_loss: 1.7107 - val_accuracy: 0.5168\n",
            "Epoch 29/50\n",
            "95/95 [==============================] - 43s 447ms/step - loss: 1.5728 - accuracy: 0.5573 - val_loss: 1.6840 - val_accuracy: 0.5145\n",
            "Epoch 30/50\n",
            "95/95 [==============================] - 43s 452ms/step - loss: 1.5684 - accuracy: 0.5580 - val_loss: 1.6803 - val_accuracy: 0.5226\n",
            "Epoch 31/50\n",
            "95/95 [==============================] - 44s 459ms/step - loss: 1.5186 - accuracy: 0.5646 - val_loss: 1.6428 - val_accuracy: 0.5343\n",
            "Epoch 32/50\n",
            "95/95 [==============================] - 43s 448ms/step - loss: 1.5384 - accuracy: 0.5593 - val_loss: 1.6730 - val_accuracy: 0.5099\n",
            "Epoch 33/50\n",
            "95/95 [==============================] - 42s 445ms/step - loss: 1.5153 - accuracy: 0.5679 - val_loss: 1.6537 - val_accuracy: 0.5192\n",
            "Epoch 34/50\n",
            "95/95 [==============================] - 43s 456ms/step - loss: 1.5030 - accuracy: 0.5643 - val_loss: 1.6505 - val_accuracy: 0.5122\n",
            "Epoch 35/50\n",
            "95/95 [==============================] - 41s 433ms/step - loss: 1.4979 - accuracy: 0.5570 - val_loss: 1.6494 - val_accuracy: 0.5238\n",
            "Epoch 36/50\n",
            "95/95 [==============================] - 43s 451ms/step - loss: 1.4876 - accuracy: 0.5696 - val_loss: 1.6821 - val_accuracy: 0.5157\n",
            "Epoch 37/50\n",
            "95/95 [==============================] - 43s 448ms/step - loss: 1.4528 - accuracy: 0.5911 - val_loss: 1.6301 - val_accuracy: 0.5226\n",
            "Epoch 38/50\n",
            "95/95 [==============================] - 43s 449ms/step - loss: 1.4787 - accuracy: 0.5808 - val_loss: 1.6346 - val_accuracy: 0.5168\n",
            "Epoch 39/50\n",
            "95/95 [==============================] - 43s 444ms/step - loss: 1.4631 - accuracy: 0.5838 - val_loss: 1.6008 - val_accuracy: 0.5401\n",
            "Epoch 40/50\n",
            "95/95 [==============================] - 43s 455ms/step - loss: 1.4312 - accuracy: 0.5974 - val_loss: 1.5917 - val_accuracy: 0.5285\n",
            "Epoch 41/50\n",
            "95/95 [==============================] - 43s 450ms/step - loss: 1.4310 - accuracy: 0.5977 - val_loss: 1.6371 - val_accuracy: 0.5192\n",
            "Epoch 42/50\n",
            "95/95 [==============================] - 42s 436ms/step - loss: 1.3848 - accuracy: 0.6064 - val_loss: 1.5573 - val_accuracy: 0.5354\n",
            "Epoch 43/50\n",
            "95/95 [==============================] - 43s 449ms/step - loss: 1.3962 - accuracy: 0.6007 - val_loss: 1.5893 - val_accuracy: 0.5436\n",
            "Epoch 44/50\n",
            "95/95 [==============================] - 43s 453ms/step - loss: 1.4055 - accuracy: 0.6090 - val_loss: 1.5421 - val_accuracy: 0.5679\n",
            "Epoch 45/50\n",
            "95/95 [==============================] - 42s 445ms/step - loss: 1.3723 - accuracy: 0.6064 - val_loss: 1.5702 - val_accuracy: 0.5366\n",
            "Epoch 46/50\n",
            "95/95 [==============================] - 43s 454ms/step - loss: 1.3562 - accuracy: 0.6170 - val_loss: 1.5432 - val_accuracy: 0.5540\n",
            "Epoch 47/50\n",
            "95/95 [==============================] - 43s 449ms/step - loss: 1.3555 - accuracy: 0.6246 - val_loss: 1.5613 - val_accuracy: 0.5563\n",
            "Epoch 48/50\n",
            "95/95 [==============================] - 42s 445ms/step - loss: 1.3380 - accuracy: 0.6229 - val_loss: 1.5387 - val_accuracy: 0.5575\n",
            "Epoch 49/50\n",
            "95/95 [==============================] - 42s 446ms/step - loss: 1.3661 - accuracy: 0.6110 - val_loss: 1.5648 - val_accuracy: 0.5482\n",
            "Epoch 50/50\n",
            "95/95 [==============================] - 43s 454ms/step - loss: 1.3338 - accuracy: 0.6272 - val_loss: 1.5926 - val_accuracy: 0.5587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir =data_dir + '/valid'\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(64, 64, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.4))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.5))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.6))  # Decreased dropout\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.Dropout(0.5))  # Decreased dropout\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# ... (previous code remains unchanged)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define Early Stopping Callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with augmented data and adjusted dropout\n",
        "history = cnn.fit(train_dataset, validation_data=valid_dataset, epochs=50, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "_BiRxg1q-STo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "c6ea8779-4c2e-46d2-a4f7-47c9c2ba72ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 images belonging to 5 classes.\n",
            "Found 861 images belonging to 5 classes.\n",
            "Epoch 1/50\n",
            "95/95 [==============================] - 45s 446ms/step - loss: 3.3918 - accuracy: 0.2850 - val_loss: 2.8019 - val_accuracy: 0.2253\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - ETA: 0s - loss: 2.9295 - accuracy: 0.3482"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5ff968502788>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Fit the model with augmented data and adjusted dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1830\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m                         )\n\u001b[0;32m-> 1832\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1833\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Create data generators with aggressive augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define the model architecture\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(64, 64, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.3))\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.4))\n",
        "\n",
        "cnn.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.BatchNormalization())\n",
        "cnn.add(layers.Dropout(0.5))\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.Dropout(0.4))\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define Early Stopping Callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with aggressive data augmentation and adjusted dropout\n",
        "history = cnn.fit(train_dataset, validation_data=valid_dataset, epochs=50, callbacks=[early_stop])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "zuwCREfP18RZ",
        "outputId": "afe20ee0-b34f-4cb9-d5a9-076acc91a5b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 images belonging to 5 classes.\n",
            "Found 861 images belonging to 5 classes.\n",
            "Epoch 1/50\n",
            "95/95 [==============================] - 47s 462ms/step - loss: 2.7534 - accuracy: 0.3260 - val_loss: 2.3531 - val_accuracy: 0.2253\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - 44s 465ms/step - loss: 2.4135 - accuracy: 0.3946 - val_loss: 2.9500 - val_accuracy: 0.2253\n",
            "Epoch 3/50\n",
            "95/95 [==============================] - 43s 453ms/step - loss: 2.2409 - accuracy: 0.4192 - val_loss: 2.4054 - val_accuracy: 0.2427\n",
            "Epoch 4/50\n",
            "95/95 [==============================] - 50s 518ms/step - loss: 2.1328 - accuracy: 0.4235 - val_loss: 2.3615 - val_accuracy: 0.3484\n",
            "Epoch 5/50\n",
            "10/95 [==>...........................] - ETA: 55s - loss: 2.1967 - accuracy: 0.4161"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4d79ed416ed2>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Fit the model with aggressive data augmentation and adjusted dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "# Create data generators with aggressive augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(64, 64, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.Dropout(0.5))\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.Dropout(0.5))\n",
        "\n",
        "cnn.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.Dropout(0.5))\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn.add(layers.Dropout(0.5))\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "# Fit the model with aggressive data augmentation and adjusted dropout\n",
        "history = cnn.fit(train_dataset, validation_data=valid_dataset, epochs=50, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bKL45s22pu",
        "outputId": "d5e79640-d790-4637-e8b1-7dff775632df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3018 images belonging to 5 classes.\n",
            "Found 861 images belonging to 5 classes.\n",
            "Epoch 1/50\n",
            "95/95 [==============================] - 42s 433ms/step - loss: 2.0551 - accuracy: 0.2144 - val_loss: 1.9810 - val_accuracy: 0.2288\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - 43s 451ms/step - loss: 1.9765 - accuracy: 0.2290 - val_loss: 1.9705 - val_accuracy: 0.2346\n",
            "Epoch 3/50\n",
            "95/95 [==============================] - 43s 452ms/step - loss: 1.9609 - accuracy: 0.2492 - val_loss: 1.9609 - val_accuracy: 0.2520\n",
            "Epoch 4/50\n",
            "95/95 [==============================] - 40s 424ms/step - loss: 1.9249 - accuracy: 0.2780 - val_loss: 1.9199 - val_accuracy: 0.4065\n",
            "Epoch 5/50\n",
            "95/95 [==============================] - 43s 447ms/step - loss: 1.8421 - accuracy: 0.3257 - val_loss: 1.8325 - val_accuracy: 0.3995\n",
            "Epoch 6/50\n",
            "95/95 [==============================] - 43s 452ms/step - loss: 1.7407 - accuracy: 0.3665 - val_loss: 1.7325 - val_accuracy: 0.4030\n",
            "Epoch 7/50\n",
            "95/95 [==============================] - 42s 444ms/step - loss: 1.6792 - accuracy: 0.4006 - val_loss: 1.6887 - val_accuracy: 0.4239\n",
            "Epoch 8/50\n",
            "95/95 [==============================] - 41s 423ms/step - loss: 1.6544 - accuracy: 0.4139 - val_loss: 1.6707 - val_accuracy: 0.4460\n",
            "Epoch 9/50\n",
            "95/95 [==============================] - 39s 411ms/step - loss: 1.6316 - accuracy: 0.4198 - val_loss: 1.6449 - val_accuracy: 0.4286\n",
            "Epoch 10/50\n",
            "95/95 [==============================] - 43s 447ms/step - loss: 1.6227 - accuracy: 0.4201 - val_loss: 1.6330 - val_accuracy: 0.4483\n",
            "Epoch 11/50\n",
            "95/95 [==============================] - 42s 444ms/step - loss: 1.5924 - accuracy: 0.4374 - val_loss: 1.6208 - val_accuracy: 0.4332\n",
            "Epoch 12/50\n",
            "95/95 [==============================] - 40s 422ms/step - loss: 1.5825 - accuracy: 0.4457 - val_loss: 1.6007 - val_accuracy: 0.4228\n",
            "Epoch 13/50\n",
            "95/95 [==============================] - 43s 446ms/step - loss: 1.5547 - accuracy: 0.4619 - val_loss: 1.5769 - val_accuracy: 0.4216\n",
            "Epoch 14/50\n",
            "95/95 [==============================] - 42s 436ms/step - loss: 1.5407 - accuracy: 0.4546 - val_loss: 1.5714 - val_accuracy: 0.4321\n",
            "Epoch 15/50\n",
            "95/95 [==============================] - 42s 439ms/step - loss: 1.5192 - accuracy: 0.4775 - val_loss: 1.5495 - val_accuracy: 0.4553\n",
            "Epoch 16/50\n",
            "95/95 [==============================] - 42s 442ms/step - loss: 1.5082 - accuracy: 0.4768 - val_loss: 1.5350 - val_accuracy: 0.4564\n",
            "Epoch 17/50\n",
            "95/95 [==============================] - 42s 437ms/step - loss: 1.5022 - accuracy: 0.4887 - val_loss: 1.5183 - val_accuracy: 0.4901\n",
            "Epoch 18/50\n",
            "95/95 [==============================] - 42s 444ms/step - loss: 1.4883 - accuracy: 0.4788 - val_loss: 1.5088 - val_accuracy: 0.4727\n",
            "Epoch 19/50\n",
            "95/95 [==============================] - 41s 428ms/step - loss: 1.4718 - accuracy: 0.4954 - val_loss: 1.4887 - val_accuracy: 0.4808\n",
            "Epoch 20/50\n",
            "95/95 [==============================] - 41s 423ms/step - loss: 1.4509 - accuracy: 0.5070 - val_loss: 1.4885 - val_accuracy: 0.4762\n",
            "Epoch 21/50\n",
            "95/95 [==============================] - 42s 448ms/step - loss: 1.4306 - accuracy: 0.5172 - val_loss: 1.4546 - val_accuracy: 0.4983\n",
            "Epoch 22/50\n",
            "95/95 [==============================] - 40s 421ms/step - loss: 1.4258 - accuracy: 0.5089 - val_loss: 1.4464 - val_accuracy: 0.4948\n",
            "Epoch 23/50\n",
            "95/95 [==============================] - 41s 430ms/step - loss: 1.4159 - accuracy: 0.5252 - val_loss: 1.4343 - val_accuracy: 0.5238\n",
            "Epoch 24/50\n",
            "95/95 [==============================] - 42s 435ms/step - loss: 1.4083 - accuracy: 0.5361 - val_loss: 1.4218 - val_accuracy: 0.5134\n",
            "Epoch 25/50\n",
            "95/95 [==============================] - 41s 431ms/step - loss: 1.3828 - accuracy: 0.5318 - val_loss: 1.4159 - val_accuracy: 0.5226\n",
            "Epoch 26/50\n",
            "95/95 [==============================] - 42s 439ms/step - loss: 1.3728 - accuracy: 0.5520 - val_loss: 1.4085 - val_accuracy: 0.5029\n",
            "Epoch 27/50\n",
            "95/95 [==============================] - 41s 429ms/step - loss: 1.3558 - accuracy: 0.5553 - val_loss: 1.4115 - val_accuracy: 0.5134\n",
            "Epoch 28/50\n",
            "95/95 [==============================] - 42s 438ms/step - loss: 1.3521 - accuracy: 0.5540 - val_loss: 1.3831 - val_accuracy: 0.5296\n",
            "Epoch 29/50\n",
            "95/95 [==============================] - 40s 416ms/step - loss: 1.3409 - accuracy: 0.5533 - val_loss: 1.3800 - val_accuracy: 0.5226\n",
            "Epoch 30/50\n",
            "95/95 [==============================] - 42s 444ms/step - loss: 1.3175 - accuracy: 0.5646 - val_loss: 1.3798 - val_accuracy: 0.5168\n",
            "Epoch 31/50\n",
            "95/95 [==============================] - 42s 438ms/step - loss: 1.3173 - accuracy: 0.5722 - val_loss: 1.3648 - val_accuracy: 0.5331\n",
            "Epoch 32/50\n",
            "95/95 [==============================] - 42s 437ms/step - loss: 1.3127 - accuracy: 0.5696 - val_loss: 1.3570 - val_accuracy: 0.5366\n",
            "Epoch 33/50\n",
            "95/95 [==============================] - 42s 435ms/step - loss: 1.2995 - accuracy: 0.5746 - val_loss: 1.3419 - val_accuracy: 0.5494\n",
            "Epoch 34/50\n",
            "95/95 [==============================] - 42s 438ms/step - loss: 1.2924 - accuracy: 0.5752 - val_loss: 1.3253 - val_accuracy: 0.5505\n",
            "Epoch 35/50\n",
            "95/95 [==============================] - 42s 443ms/step - loss: 1.2823 - accuracy: 0.5832 - val_loss: 1.3321 - val_accuracy: 0.5459\n",
            "Epoch 36/50\n",
            "95/95 [==============================] - 42s 444ms/step - loss: 1.2720 - accuracy: 0.5828 - val_loss: 1.3165 - val_accuracy: 0.5447\n",
            "Epoch 37/50\n",
            "95/95 [==============================] - 42s 435ms/step - loss: 1.2499 - accuracy: 0.5808 - val_loss: 1.3185 - val_accuracy: 0.5424\n",
            "Epoch 38/50\n",
            "95/95 [==============================] - 42s 434ms/step - loss: 1.2652 - accuracy: 0.5772 - val_loss: 1.3161 - val_accuracy: 0.5505\n",
            "Epoch 39/50\n",
            "95/95 [==============================] - 42s 441ms/step - loss: 1.2539 - accuracy: 0.5968 - val_loss: 1.2978 - val_accuracy: 0.5552\n",
            "Epoch 40/50\n",
            "95/95 [==============================] - 39s 415ms/step - loss: 1.2439 - accuracy: 0.5855 - val_loss: 1.2825 - val_accuracy: 0.5563\n",
            "Epoch 41/50\n",
            "95/95 [==============================] - 41s 432ms/step - loss: 1.2297 - accuracy: 0.5858 - val_loss: 1.2901 - val_accuracy: 0.5505\n",
            "Epoch 42/50\n",
            "95/95 [==============================] - 42s 436ms/step - loss: 1.2221 - accuracy: 0.6070 - val_loss: 1.2787 - val_accuracy: 0.5598\n",
            "Epoch 43/50\n",
            "95/95 [==============================] - 47s 491ms/step - loss: 1.2117 - accuracy: 0.5964 - val_loss: 1.2805 - val_accuracy: 0.5598\n",
            "Epoch 44/50\n",
            "95/95 [==============================] - 42s 439ms/step - loss: 1.2216 - accuracy: 0.5888 - val_loss: 1.2592 - val_accuracy: 0.5807\n",
            "Epoch 45/50\n",
            "95/95 [==============================] - 42s 446ms/step - loss: 1.2067 - accuracy: 0.6007 - val_loss: 1.2409 - val_accuracy: 0.5842\n",
            "Epoch 46/50\n",
            "95/95 [==============================] - 40s 424ms/step - loss: 1.1911 - accuracy: 0.6163 - val_loss: 1.2474 - val_accuracy: 0.5738\n",
            "Epoch 47/50\n",
            "95/95 [==============================] - 42s 434ms/step - loss: 1.1990 - accuracy: 0.6034 - val_loss: 1.2510 - val_accuracy: 0.5738\n",
            "Epoch 48/50\n",
            "95/95 [==============================] - 42s 441ms/step - loss: 1.1840 - accuracy: 0.5977 - val_loss: 1.2561 - val_accuracy: 0.5656\n",
            "Epoch 49/50\n",
            "95/95 [==============================] - 40s 419ms/step - loss: 1.1858 - accuracy: 0.6027 - val_loss: 1.2184 - val_accuracy: 0.5912\n",
            "Epoch 50/50\n",
            "95/95 [==============================] - 42s 443ms/step - loss: 1.1745 - accuracy: 0.6080 - val_loss: 1.2005 - val_accuracy: 0.6098\n"
          ]
        }
      ]
    }
  ]
}